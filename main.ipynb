{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf_8 -*-\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers import BatchNormalization, Lambda, AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D, Activation, concatenate\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.applications.densenet import preprocess_input\n",
    "import cv2\n",
    "\n",
    "from model import *\n",
    "from custom_loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return preprocess_input(img)\n",
    "\n",
    "\n",
    "def get_feature(model, DB_path):\n",
    "\n",
    "    img_size = (224, 224)\n",
    "\n",
    "    intermediate_model = Model(\n",
    "        inputs=model.input, outputs=model.layers[-2].output)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess, dtype='float32')\n",
    "\n",
    "    db_generator = test_datagen.flow_from_directory(\n",
    "        directory=DB_path,\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "    db_vecs = intermediate_model.predict_generator(db_generator,\n",
    "                                                   steps=len(\n",
    "                                                       reference_generator),\n",
    "                                                   verbose=1)\n",
    "\n",
    "    return db_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Descriptor():\n",
    "    def __init__(self, config):\n",
    "\n",
    "        self.input_shape = config.input_shape\n",
    "        self.sbow_shape = config.sbow_shape\n",
    "        self.num_classes = config.num_classes\n",
    "        self.batch_size = config.batch_size\n",
    "        self.nb_epoch = config.epoch\n",
    "\n",
    "        self.model = base_model(self.input_shape, self.num_classes)\n",
    "\n",
    "    def train(self, dataset_path, datagen, checkpoint_path, checkpoint_inteval):\n",
    "\n",
    "        opt = keras.optimizers.Adam(amsgrad=True)\n",
    "\n",
    "        model.compile(loss=ArcFaceloss, optimizer=opt)\n",
    "\n",
    "        train_generator = datagen.flow_from_directory(\n",
    "            directory=dataset_path,\n",
    "            target_size=self.input_shape[:2],\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "            shuffle=True,\n",
    "            subset='training')\n",
    "\n",
    "        val_generator = datagen.flow_from_directory(\n",
    "            directory=dataset_path,\n",
    "            target_size=input_shape[:2],\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "            shuffle=True,\n",
    "            subset='validation')\n",
    "\n",
    "        \"\"\" Callback \"\"\"\n",
    "        monitor = 'loss'\n",
    "        reduce_lr = ReduceLROnPlateau(monitor=monitor, patience=4)\n",
    "\n",
    "        \"\"\" Training loop \"\"\"\n",
    "        STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "        STEP_SIZE_VAL = val_generator.n // val_generator.batch_size\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        for epoch in range(nb_epoch):\n",
    "            t1 = time.time()\n",
    "            res = model.fit_generator(generator=train_generator,\n",
    "                                      steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                      initial_epoch=epoch,\n",
    "                                      validation_data=val_generator,\n",
    "                                      validation_steps=STEP_SIZE_VAL,\n",
    "                                      epochs=epoch + 1,\n",
    "                                      callbacks=[reduce_lr],\n",
    "                                      verbose=1,\n",
    "                                      shuffle=True)\n",
    "            t2 = time.time()\n",
    "            print(res.history)\n",
    "            print('Training time for one epoch : %.1f' % ((t2 - t1)))\n",
    "\n",
    "            if epoch % checkpoint_inteval == 0:\n",
    "                model.save(checkpoint_path + str(epoch) + \".hdf5\")\n",
    "        model.save(checkpoint_path + \"finish.hdf5\")\n",
    "        print('Total training time : %.1f' % (time.time() - t0))\n",
    "\n",
    "    def updateDB(model_path, DB_path, reference_path):\n",
    "\n",
    "        db = [os.path.join(DB_path, path) for path in os.listdir(DB_path)]\n",
    "\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        features = get_feature(model, DB_path)\n",
    "\n",
    "        reference = pd.DataFrame()\n",
    "\n",
    "        reference[\"img\"] = db\n",
    "        reference[\"feature\"] = features\n",
    "\n",
    "        reference.to_csv(reference_path, index=False)\n",
    "\n",
    "        print(\"UPDATE COMPLETE\")\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters\n",
    "    args.add_argument('--epoch', type=int, default=100)\n",
    "    args.add_argument('--batch_size', type=int, default=64)\n",
    "    args.add_argument('--num_classes', type=int, default=1383)\n",
    "    args.add_argument('--input_shape', type=int, default=(224, 224, 3))\n",
    "    args.add_argument('--sbow', type=int, default=(128,))\n",
    "    args.add_argument('--train', type=bool, default=False)\n",
    "    args.add_argument('--updateDB', type=str, default=None)\n",
    "    args.add_argument('--DB_path', type=str, default=None)\n",
    "    args.add_argument('--model_path', type=str,\n",
    "                      default=\"./checkpoint/finish.hdf5\")\n",
    "    args.add_argument('--dataset_path', type=str, default=\"./data/images/\")\n",
    "    args.add_argument('--checkpoint_path', type=str, default=\"./checkpoint/\")\n",
    "    args.add_argument('--checkpoint_inteval', type=int, default=10)\n",
    "    args.add_argument('--reference_path', type=str, default=\"./\")\n",
    "\n",
    "    config = args.parse_args()\n",
    "\n",
    "    descriptor = Descriptor(config)\n",
    "\n",
    "    if config.train:\n",
    "\n",
    "        datagen = ImageDataGenerator(preprocessing_function=preprocess,\n",
    "                                     zoom_range=0.2, vertical_flip=True, horizontal_flip=True,\n",
    "                                     validation_split=0.1)\n",
    "\n",
    "        descriptor.train(config.dataset_path, datagen,\n",
    "                         check_point=config.checkpoint_path, check_interval=config.checkpoint_inteval)\n",
    "\n",
    "    if config.updateDB:\n",
    "        descriptor.updateDB(config.model_path,\n",
    "                            config.DB_path, config.reference_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
